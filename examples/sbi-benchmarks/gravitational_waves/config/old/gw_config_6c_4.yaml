
# Flux1 Training Configuration
# this is a good and working model


task_name: gw

strategy:
  method: "flow"
  model: "flux"

optimizer:
  warmup_steps: 500
  decay_transition: 0.80
  max_lr: 1.0e-4
  min_lr: 1.0e-6

model:
  in_channels: 1
  vec_in_dim: null
  context_in_dim: 128
  mlp_ratio: 4
  num_heads: 4
  depth: 8
  depth_single_blocks: 16
  axes_dim: [10]
  qkv_bias: true
  params_dtype: "bfloat16"
  id_embedding_strategy: ["absolute", "pos1d"]

vae_model:
  resolution: 8192
  in_channels: 2
  ch: 32
  out_ch: 2
  ch_mult: [
            1,  # 8192
            2,  # 4096
            4,  # 2048
            8,  # 1024
            16,  # 512
            16,  # 256
            16,  # 128
            16,  # 64
            # 16, # 32
            # 16, # 16
            # 16, # 8
            # 16, # 4
        ]
  num_res_blocks: 1
  z_channels: 128
  scale_factor: 1.0
  shift_factor: 0.0
  params_dtype: "bfloat16"

training:
  batch_size: 256
  nsteps: 10000
  ema_decay: 0.999
  multistep: 1
  early_stopping: false
  val_every: 100
  experiment_id: 4
  restore_model: false
  train_model: true