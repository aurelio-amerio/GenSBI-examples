{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712455a8",
   "metadata": {},
   "source": [
    "# Two Moons Flux1 Score Matching Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16110fe5",
   "metadata": {},
   "source": [
    "---\n",
    "This notebook demonstrates conditional Score Matching on the Two Moons task using JAX and Flax. \n",
    "\n",
    "**About Simulation-Based Inference (SBI):** SBI refers to a class of methods for inferring parameters of complex models when the likelihood function is intractable, but simulation is possible. SBI algorithms learn to approximate the posterior distribution over parameters given observed data, enabling inference in scientific and engineering domains where traditional methods fail.\n",
    "\n",
    "**The Two Moons Dataset:**\n",
    "The Two Moons dataset is a two-dimensional simulation-based inference benchmark designed to test an algorithm's ability to handle complex posterior distributions. Its posterior is both bimodal (two distinct peaks) and locally crescent-shaped, making it a challenging task for inference algorithms. The primary purpose of this benchmark is to evaluate how well different methods can capture and represent multimodality and intricate structure in the posterior.\n",
    "\n",
    "**Purpose of This Notebook:**\n",
    "This notebook trains and evaluates a Flux1 Score Matching model on the Two Moons task. The goal is to assess the model's ability to learn and represent a non-trivial posterior distribution with both global (bimodal) and local (crescent-shaped) complexity.\n",
    "\n",
    "## Table of Contents\n",
    "| Section | Description |\n",
    "|---|---|\n",
    "| 1. [Introduction & Setup](#introduction-setup) | Overview, environment, device, autoreload |\n",
    "| 2. [Task & Data Preparation](#task-data-preparation) | Define task, visualize data, create datasets |\n",
    "| 3. [Model Configuration & Definition](#model-configuration-definition) | Load config, set parameters, instantiate model |\n",
    "| 4. [Training](#training) | Train or restore model, manage checkpoints |\n",
    "| 5. [Evaluation & Visualization](#evaluation-visualization) | Visualize loss, sample posterior, compute log prob |\n",
    "| 6. [Posterior Calibration Checks](#posterior-calibration-checks) | Marginal coverage, TARP, SBC, L-C2ST |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fc445",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "---\n",
    "In this section, we introduce the problem, set up the computational environment, import required libraries, configure JAX for CPU or GPU usage, and enable autoreload for iterative development. Compatibility with Google Colab is also ensured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab and install dependencies if needed\n",
    "try:\n",
    "    import google.colab\n",
    "    colab = True\n",
    "except ImportError:\n",
    "    colab = False\n",
    "\n",
    "if colab:\n",
    "    # Install required packages and clone the repository\n",
    "    %pip install --quiet \"gensbi[cuda12, examples] @ git+https://github.com/aurelio-amerio/GenSBI\"\n",
    "    !git clone --depth 1 https://github.com/aurelio-amerio/GenSBI-examples\n",
    "    %cd GenSBI-examples/examples/sbi-benchmarks/two_moons/diffusion_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# select device\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cuda\" \n",
    "# os.environ[\"JAX_PLATFORMS\"] = \"cpu\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf17d469",
   "metadata": {},
   "source": [
    "## 2. Task & Data Preparation \n",
    "---\n",
    "In this section, we define the Two Moons task, visualize reference samples, and create the training and validation datasets required for model learning. Batch size and sample count are set for reproducibility and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_model=True\n",
    "train_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "# get the current notebook path\n",
    "notebook_path = os.getcwd()\n",
    "checkpoint_dir = os.path.join(notebook_path, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ec637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "from numpyro import distributions as dist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.utils.plotting import plot_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899530ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi_examples.tasks import TwoMoons\n",
    "task = TwoMoons(kind=\"conditional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference posterior for an observation\n",
    "obs, reference_samples = task.get_reference(num_observation=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f273cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 2D posterior \n",
    "plot_marginals(np.asarray(reference_samples, dtype=np.float32), gridsize=50,range=[(-1,0),(0,1)], plot_levels=False, backend=\"seaborn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset\n",
    "nsamples = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for training. Larger batch sizes help prevent overfitting, but are limited by available GPU memory.\n",
    "batch_size = 4096\n",
    "# Create training and validation datasets using the Two Moons task object.\n",
    "train_dataset = task.get_train_dataset(batch_size)\n",
    "val_dataset = task.get_val_dataset(batch_size)\n",
    "\n",
    "# Create iterators for the training and validation datasets.\n",
    "dataset_iter = iter(train_dataset)\n",
    "val_dataset_iter = iter(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ef83c",
   "metadata": {},
   "source": [
    "## 3. Model Configuration & Definition \n",
    "---\n",
    "In this section, we load the model and optimizer configuration, set all relevant parameters, and instantiate the Flux1 model. Edge masks and marginalization functions are used for flexible inference and posterior estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.recipes import Flux1DiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0121e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Path to the Flux1 Score Matching configuration file.\n",
    "config_path = f\"{notebook_path}/config/config_diffusion_flux.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef215fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dimensionality information from the task object.\n",
    "dim_obs = task.dim_obs  # Number of parameters to infer\n",
    "dim_cond = task.dim_cond    # Number of observed data dimensions\n",
    "\n",
    "dim_joint = dim_obs + dim_cond  # Joint dimension (for model input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1832f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Flux1DiffusionPipeline.init_pipeline_from_config(\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        dim_obs,\n",
    "        dim_cond,\n",
    "        config_path,\n",
    "        checkpoint_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd3e79",
   "metadata": {},
   "source": [
    "## 4. Training \n",
    "---\n",
    "In this section, we train the Score Matching model or restore a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aad395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.train(nnx.Rngs(0), 5, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.restore_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73781fa0",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Visualization \n",
    "---\n",
    "In this section, we evaluate the trained Simformer model by sampling from the posterior, and comparing results to reference data. We also compute and visualize the unnormalized log probability over a grid to assess model calibration and density estimation. These analyses provide insight into model performance and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8987177",
   "metadata": {},
   "source": [
    "### Section 5.1: Posterior Sampling\n",
    "---\n",
    "In this section, we sample from the posterior distribution using the trained model and visualize the results. Posterior samples are generated for a selected observation and compared to reference samples to assess model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to do conditional inference. We need an observation for which we want to ocmpute the posterior\n",
    "def get_samples(idx, nsamples=10_000, use_ema=False, key=None):\n",
    "    observation, reference_samples = task.get_reference(idx)\n",
    "    true_param = jnp.array(task.get_true_parameters(idx))\n",
    "\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(42)\n",
    "\n",
    "    time_grid = jnp.linspace(0,1,100)\n",
    "\n",
    "    samples = pipeline.sample(key, observation, nsamples, use_ema=use_ema, time_grid=time_grid)\n",
    "    return samples, true_param, reference_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, true_param, reference_samples =  get_samples(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09269d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape # (100, 10000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201318b6",
   "metadata": {},
   "source": [
    "### Section 5.2: Visualize Posterior Samples\n",
    "---\n",
    "In this section, we plot the posterior samples as a 2D histogram to visualize the learned distribution and compare it to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.utils.plotting import plot_marginals, plot_2d_dist_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marginals(samples[-1,...,0], plot_levels=False, backend=\"seaborn\", gridsize=50, range =[(-1., 0), (0, 1.)])\n",
    "plt.show()\n",
    "\n",
    "#Â alternatively use \"corner\" to plot containment levels too\n",
    "# plot_marginals(samples[-1,...,0], plot_levels=True, gridsize=30, range=[(-1., 0), (0, 1.)])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5c4fc",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/two_moons/diffusion_flux/imgs/marginals_ema_1.png\" width=400>\n",
    "\n",
    "### 5.3. Animations\n",
    "---\n",
    "In this section, we create and display animations of posterior samples and density contours over time. These visualizations illustrate the evolution of the learned distribution during the sampling process, providing dynamic insight into model behavior and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f07956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as imageio\n",
    "import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d708c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in tqdm(range(len(samples))):\n",
    "    fig, axes = plot_marginals(\n",
    "        samples[i,...,0],\n",
    "        plot_levels=False,\n",
    "        gridsize=50,\n",
    "        range=[(-1.0, 0), (0, 1.0)],\n",
    "        backend=\"seaborn\",\n",
    "    )\n",
    "\n",
    "    # manually set the ticks to make a prettier plot\n",
    "   \n",
    "    axes[0,0].set_ylim(0,6)\n",
    "    axes[0,0].set_yticks([5])\n",
    "\n",
    "    axes[1,1].set_xlim(0,6)\n",
    "    axes[1,1].set_xticks([5])\n",
    "\n",
    "    axes[1,1].text(0, 1.03, f\"t = {(i+1)/len(samples):.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", dpi=300)\n",
    "    buf.seek(0)\n",
    "    image = imageio.imread(buf)\n",
    "    buf.close()\n",
    "    if i == 0:\n",
    "        images = []\n",
    "    images.append(image)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the last frame 10 times to make the gif pause at the end\n",
    "images += [images[-1]] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imwrite(\n",
    "    'animated_plot_samples.gif', \n",
    "    images, \n",
    "    duration=5000/len(images), \n",
    "    loop=0  # 0 means loop indefinitely\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f793b",
   "metadata": {},
   "source": [
    "## 6. Posterior Calibration Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, module=\"google.protobuf.runtime_version\"\n",
    ")\n",
    "\n",
    "from gensbi.diagnostics import run_sbc, sbc_rank_plot\n",
    "from gensbi.diagnostics import run_tarp, plot_tarp\n",
    "from gensbi.diagnostics.marginal_coverage import compute_marginal_coverage, plot_marginal_coverage\n",
    "from gensbi.diagnostics import LC2ST, plot_lc2st\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5214c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_calibration_samples = 200 #excercise: try 500, what changes?\n",
    "num_posterior_samples = 1000 #excercise: try 10_000, what changes?\n",
    "\n",
    "# Get test data\n",
    "data = task.dataset[\"test\"].with_format(\"jax\")[:num_calibration_samples]\n",
    "xs = jnp.asarray(data[\"xs\"], dtype=jnp.bfloat16)\n",
    "thetas = jnp.asarray(data[\"thetas\"], dtype=jnp.bfloat16)\n",
    "\n",
    "print(f\"Sampling {num_posterior_samples} posterior samples for {num_calibration_samples} observations...\")\n",
    "\n",
    "# Generate posterior samples in batch\n",
    "posterior_samples = pipeline.sample_batched(\n",
    "    jax.random.PRNGKey(12345), xs, num_posterior_samples, use_ema=True\n",
    ")\n",
    "\n",
    "# Reshape for analysis\n",
    "xs = xs.reshape((xs.shape[0], -1))\n",
    "thetas = thetas.reshape((thetas.shape[0], -1))\n",
    "posterior_samples = posterior_samples.reshape(\n",
    "    (posterior_samples.shape[0], posterior_samples.shape[1], -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ce78f",
   "metadata": {},
   "source": [
    "### 6.1. Marginal coverage\n",
    "In this test, we compare the expected confidence level $z$ with the empirical coverage level $\\hat{z}$ for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_marginal = compute_marginal_coverage(thetas, posterior_samples, method=\"histogram\")\n",
    "plot_marginal_coverage(alpha_marginal)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606b418",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/two_moons/diffusion_flux/imgs/marginal_coverage_1.png\" width=800>\n",
    "\n",
    "### 6.2. TARP (Test of Accuracy and Reliability of Posterior)\n",
    "We calculate the Expected Coverage Probability (ECP) to assess the calibration of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running TARP diagnostic...\")\n",
    "\n",
    "# Calculate ECP and Alpha\n",
    "tarp_result = run_tarp(\n",
    "    thetas,\n",
    "    posterior_samples,\n",
    "    references=None,  # will be calculated automatically.\n",
    ")\n",
    "\n",
    "# Plot TARP\n",
    "plot_tarp(tarp_result)\n",
    "plt.title(\"TARP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8319c6",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/two_moons/diffusion_flux/imgs/tarp_1.png\" width=800>\n",
    "\n",
    "### 6.3. SBC (Simulation-Based Calibration)\n",
    "We check the uniformity of the rank statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb769a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running SBC diagnostic...\")\n",
    "\n",
    "# Compute ranks\n",
    "ranks, dap_samples = run_sbc(thetas, xs, posterior_samples)\n",
    "\n",
    "# Plot SBC\n",
    "f, ax = sbc_rank_plot(ranks, num_posterior_samples, plot_type=\"hist\", num_bins=20)\n",
    "plt.suptitle(\"SBC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a30c8",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/two_moons/diffusion_flux/imgs/sbc_1.png\" width=500>\n",
    "\n",
    "### 6.4. L-C2ST (Local Classifier 2-Sample Test)\n",
    "We train a classifier to distinguish between true and sampled parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e476c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running L-C2ST diagnostic...\")\n",
    "\n",
    "# 1. Prepare data for LC2ST\n",
    "# We use a slightly larger set for training the classifier, but single sample per observation\n",
    "num_lc2st_data = 10000\n",
    "data_lc2st = task.dataset[\"test\"].with_format(\"jax\")[:num_lc2st_data]\n",
    "xs_lc2st = jnp.asarray(data_lc2st[\"xs\"], dtype=jnp.bfloat16)\n",
    "thetas_lc2st = jnp.asarray(data_lc2st[\"thetas\"], dtype=jnp.bfloat16)\n",
    "\n",
    "# Sample 1 posterior sample per observation\n",
    "posterior_samples_lc2st = pipeline.sample(\n",
    "    jax.random.PRNGKey(43), xs_lc2st, num_lc2st_data, use_ema=True\n",
    ")\n",
    "\n",
    "# Reshape\n",
    "thetas_lc2st_flat = thetas_lc2st.reshape(thetas_lc2st.shape[0], -1)\n",
    "xs_lc2st_flat = xs_lc2st.reshape(xs_lc2st.shape[0], -1)\n",
    "posterior_samples_lc2st_flat = posterior_samples_lc2st.reshape(posterior_samples_lc2st.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c423a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train the L-C2ST classifier\n",
    "# Validation split happens inside LC2ST or we can hold out manually. \n",
    "# Here we hold out the last sample for visualization.\n",
    "lc2st = LC2ST(\n",
    "    thetas=thetas_lc2st_flat[:-1],\n",
    "    xs=xs_lc2st_flat[:-1],\n",
    "    posterior_samples=posterior_samples_lc2st_flat[:-1],\n",
    "    classifier=\"mlp\",\n",
    "    num_ensemble=1,\n",
    ")\n",
    "\n",
    "print(\"Training classifier under null hypothesis...\")\n",
    "_ = lc2st.train_under_null_hypothesis()\n",
    "print(\"Training classifier on observed data...\")\n",
    "_ = lc2st.train_on_observed_data()\n",
    "\n",
    "# 3. Visualize on a held-out observation\n",
    "x_o_star = xs_lc2st[-1:]\n",
    "theta_o_star = thetas_lc2st[-1:]\n",
    "\n",
    "# Sample many points for this specific observation to visualize the local score landscape\n",
    "print(\"Sampling for visualization...\")\n",
    "post_samples_star = pipeline.sample(\n",
    "    jax.random.PRNGKey(44), x_o_star[0], 10_000, use_ema=True\n",
    ")\n",
    "\n",
    "# Flatten for plotting\n",
    "x_o_star_flat = x_o_star.reshape(1, -1)\n",
    "post_samples_star_flat = np.array(\n",
    "    post_samples_star.reshape(post_samples_star.shape[0], -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_lc2st(\n",
    "    lc2st,\n",
    "    post_samples_star_flat,\n",
    "    x_o_star_flat,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d99a01",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/two_moons/diffusion_flux/imgs/lc2st_1.png\" width=500>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "gensbi",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
