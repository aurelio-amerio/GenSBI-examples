{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e2b5f2",
   "metadata": {},
   "source": [
    "# SLCP Flux1Joint Flow Example\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-amerio/GenSBI-examples/blob/main/examples/sbi-benchmarks/slcp/flow_flux1joint/slcp_flow_flux1joint.ipynb)\n",
    "> Notice: This notebook has been automatically generated. If you find any errors, please [open an issue](https://github.com/aurelio-amerio/GenSBI-examples/issues) on the GenSBI-examples GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106826ee",
   "metadata": {},
   "source": [
    "---\n",
    "This notebook demonstrates joint Flow Matching on the SLCP task using JAX and Flax. \n",
    "\n",
    "## Table of Contents\n",
    "| Section | Description |\n",
    "|---|---|\n",
    "| 1. [Introduction & Setup](#introduction-setup) | Overview, environment, device, autoreload |\n",
    "| 2. [Task & Data Preparation](#task-data-preparation) | Define task, visualize data, create datasets |\n",
    "| 3. [Model Configuration & Definition](#model-configuration-definition) | Load config, set parameters, instantiate model |\n",
    "| 4. [Training](#training) | Train or restore model, manage checkpoints |\n",
    "| 5. [Evaluation & Visualization](#evaluation-visualization) | Visualize loss, sample posterior, compute log prob |\n",
    "| 6. [Posterior Calibration Checks](#posterior-calibration-checks) | Marginal coverage, TARP, SBC, L-C2ST |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4c8cf",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "---\n",
    "In this section, we introduce the problem, set up the computational environment, import required libraries, configure JAX for CPU or GPU usage, and enable autoreload for iterative development. Compatibility with Google Colab is also ensured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab and install dependencies if needed\n",
    "try:\n",
    "    import google.colab\n",
    "    colab = True\n",
    "except ImportError:\n",
    "    colab = False\n",
    "\n",
    "if colab:\n",
    "    # Install required packages and clone the repository\n",
    "    %pip install --quiet \"gensbi[cuda12] @ git+https://github.com/aurelio-amerio/GenSBI\"\n",
    "    %pip install --quiet \"gensbi-examples @ git+https://github.com/aurelio-amerio/GenSBI-examples\"\n",
    "    !git clone --depth 1 https://github.com/aurelio-amerio/GenSBI-examples\n",
    "    %cd GenSBI-examples/examples/sbi-benchmarks/slcp/flow_flux1joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# select device\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cuda\" \n",
    "# os.environ[\"JAX_PLATFORMS\"] = \"cpu\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38549c7",
   "metadata": {},
   "source": [
    "## 2. Task & Data Preparation\n",
    "---\n",
    "In this section, we define the SLCP task, visualize reference samples, and create the training and validation datasets required for model learning. Batch size and sample count are set for reproducibility and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_model=True\n",
    "train_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "# get the current notebook path\n",
    "notebook_path = os.getcwd()\n",
    "checkpoint_dir = os.path.join(notebook_path, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "from numpyro import distributions as dist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.utils.plotting import plot_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi_examples.tasks import get_task\n",
    "task = get_task(\"slcp\", kind=\"joint\", use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference posterior for an observation\n",
    "obs, reference_samples = task.get_reference(num_observation=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e37d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 2D posterior \n",
    "plot_marginals(np.asarray(reference_samples, dtype=np.float32), gridsize=50, plot_levels=False, backend=\"seaborn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset\n",
    "nsamples = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5355fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for training. Larger batch sizes help prevent overfitting, but are limited by available GPU memory.\n",
    "batch_size = 4096\n",
    "# Create training and validation datasets using the SLCP task object.\n",
    "train_dataset = task.get_train_dataset(batch_size)\n",
    "val_dataset = task.get_val_dataset(batch_size)\n",
    "\n",
    "# Create iterators for the training and validation datasets.\n",
    "dataset_iter = iter(train_dataset)\n",
    "val_dataset_iter = iter(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a572fa7",
   "metadata": {},
   "source": [
    "## 3. Model Configuration & Definition\n",
    "---\n",
    "In this section, we load the model and optimizer configuration, set all relevant parameters, and instantiate the Flux1Joint model. Edge masks and marginalization functions are used for flexible inference and posterior estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d46cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.recipes import Flux1JointFlowPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0630fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Path to the configuration file.\n",
    "config_path = f\"{notebook_path}/config/config_flow_flux1joint.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dimensionality information from the task object.\n",
    "dim_obs = task.dim_obs  # Number of parameters to infer\n",
    "dim_cond = task.dim_cond    # Number of observed data dimensions\n",
    "\n",
    "dim_joint = task.dim_joint  # Joint dimension (for model input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Flux1JointFlowPipeline.init_pipeline_from_config(\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        dim_obs,\n",
    "        dim_cond,\n",
    "        config_path,\n",
    "        checkpoint_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad4c6f",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "---\n",
    "In this section, we train the model or restore a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.train(nnx.Rngs(0), save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24df0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.restore_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08c64c",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Visualization\n",
    "---\n",
    "In this section, we evaluate the trained Simformer model by sampling from the posterior, and comparing results to reference data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41c831",
   "metadata": {},
   "source": [
    "### Section 5.1: Posterior Sampling\n",
    "---\n",
    "In this section, we sample from the posterior distribution using the trained model and visualize the results. Posterior samples are generated for a selected observation and compared to reference samples to assess model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to do joint inference. We need an observation for which we want to ocmpute the posterior\n",
    "def get_samples(idx, nsamples=10_000, use_ema=False, key=None):\n",
    "    observation, reference_samples = task.get_reference(idx)\n",
    "    true_param = jnp.array(task.get_true_parameters(idx))\n",
    "\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(42)\n",
    "\n",
    "    time_grid = jnp.linspace(0,1,100)\n",
    "\n",
    "    samples = pipeline.sample(key, observation, nsamples, use_ema=use_ema, time_grid=time_grid)\n",
    "    return samples, true_param, reference_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, true_param, reference_samples =  get_samples(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27ed5f",
   "metadata": {},
   "source": [
    "### Section 5.2: Visualize Posterior Samples\n",
    "---\n",
    "In this section, we plot the posterior samples as a 2D histogram to visualize the learned distribution and compare it to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5acc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensbi.utils.plotting import plot_marginals, plot_2d_dist_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72852946",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marginals(samples[-1,...,0], backend=\"seaborn\", gridsize=50)\n",
    "plt.show()\n",
    "\n",
    "# alternatively use \"corner\" to plot containment levels too\n",
    "# plot_marginals(samples[-1,...,0], backend=\"corner\", gridsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05bd20",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/slcp/flow_flux1joint/imgs/marginals_ema_1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1aa5d2",
   "metadata": {},
   "source": [
    "## 6. Posterior Calibration Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f43ec3",
   "metadata": {},
   "source": [
    "We report here the results of the posterior calibration tests. As an excercise, you can implement the tests as in the Two Moons example and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb16425",
   "metadata": {},
   "source": [
    "**Average C2ST**: 0.5490 ± 0.0187"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1868bc5a",
   "metadata": {},
   "source": [
    "**Marginal Coverage:** <br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/slcp/flow_flux1joint/imgs/marginal_coverage_1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984df937",
   "metadata": {},
   "source": [
    "**TARP:** <br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/slcp/flow_flux1joint/imgs/tarp_1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd66fb17",
   "metadata": {},
   "source": [
    "**SBC** <br><br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/slcp/flow_flux1joint/imgs/sbc_1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b9a6a",
   "metadata": {},
   "source": [
    "**L-C2ST**<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/aurelio-amerio/GenSBI-examples/refs/heads/main/examples/sbi-benchmarks/slcp/flow_flux1joint/imgs/lc2st_1.png\" width=500>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "gensbi",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
